{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pK9YeoBqudM"
      },
      "source": [
        "# üçÑüçÑ Binary Prediction of Poisonous Mushrooms üçÑüçÑ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6tTdJmiqudP"
      },
      "source": [
        "![image.png](attachment:cfe04934-1c97-4ce8-8a5d-1f1215ba4473.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0H64I8xqudP"
      },
      "source": [
        "### **Data Features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sJ_qMN_qudQ"
      },
      "source": [
        "<style>\n",
        "  table {\n",
        "    font-size: 30px;\n",
        "    text-align: left;\n",
        "    width: 100%;\n",
        "  }\n",
        "  th {\n",
        "    font-weight: bold;\n",
        "    padding: 8px;\n",
        "    background-color: #f2f2f2;\n",
        "    font-size: 30px;\n",
        "  }\n",
        "  td {\n",
        "    padding: 8px;\n",
        "  }\n",
        "</style>\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Field</th>\n",
        "    <th>Description</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>id</td>\n",
        "    <td>Unique Identifier</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>class</td>\n",
        "    <td>Indicates if the mushroom is <strong>poisonous (p)</strong> or <strong>edible (e)</strong></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>cap-diameter</td>\n",
        "    <td>Diameter of the cap (in mm)</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>cap-shape</td>\n",
        "    <td>Shape of the cap</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>cap-surface</td>\n",
        "    <td>Surface texture of the cap</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>cap-color</td>\n",
        "    <td>Color of the cap</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>does-bruise-or-bleed</td>\n",
        "    <td>Indicates if the mushroom bruises or bleeds</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>gill-attachment</td>\n",
        "    <td>Attachment of the gills to the stem</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>gill-spacing</td>\n",
        "    <td>Spacing between the gills</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>gill-color</td>\n",
        "    <td>Color of the gills</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>stem-height</td>\n",
        "    <td>Height of the stem (in mm)</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>stem-width</td>\n",
        "    <td>Width of the stem (in mm)</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>stem-root</td>\n",
        "    <td>Structure of the stem's base</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>stem-surface</td>\n",
        "    <td>Surface texture of the stem</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>stem-color</td>\n",
        "    <td>Color of the stem</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>veil-type</td>\n",
        "    <td>Type of the veil on the cap</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>veil-color</td>\n",
        "    <td>Color of the veil</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>has-ring</td>\n",
        "    <td>Indicates if there is a ring on the stem</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>ring-type</td>\n",
        "    <td>Type of ring on the stem</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>spore-print-color</td>\n",
        "    <td>Color of the spore print left by the mushroom</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>habitat</td>\n",
        "    <td>The environment where the mushroom is found</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>season</td>\n",
        "    <td>The season in which the mushroom was observed</td>\n",
        "  </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "71e244JHq12b",
        "outputId": "1a8513cc-3a17-4558-cc8c-5d2f1b8e77be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb1acb14-ae58-4ca3-b9fd-bb2efbee215f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bb1acb14-ae58-4ca3-b9fd-bb2efbee215f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 2: Upload your Kaggle API key\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Step 3: Move the API key to the correct location\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Step 4: Download the dataset from the competition\n",
        "!kaggle competitions download -c playground-series-s4e8\n",
        "\n",
        "# Step 5: Unzip the dataset\n",
        "!unzip playground-series-s4e8.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYbo8cmqqudR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix, matthews_corrcoef\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYKGlrMGqudT"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ7IYWRxqudT"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5D2vIFJqudT"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mQ6enDHqudT"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4_8pOVqqudU"
      },
      "source": [
        "First We dont need ID coulmn so i will DROP it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuJANpnxqudU"
      },
      "outputs": [],
      "source": [
        "# Drop the 'id' column from both datasets\n",
        "df.drop(columns=['id'], axis=1, inplace=True)\n",
        "test_df.drop(columns=['id'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXnwAB75qudU"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pcOEa8dqudU"
      },
      "source": [
        "Good There is no duplicated\n",
        "\n",
        "Lets check the Missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvl8ouG2qudU"
      },
      "source": [
        "## Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cvo9-mshqudV"
      },
      "outputs": [],
      "source": [
        "missing_values = df.isnull().sum()\n",
        "# Calculate the percentage of missing values for each column\n",
        "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
        "\n",
        "# Display the missing values count and percentage for each column\n",
        "missing_info = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})\n",
        "print(missing_info)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zE_oZBKqudV"
      },
      "source": [
        "**The dataset has a significant amount of missing data in several columns, which requires careful consideration**\n",
        "\n",
        "#### 1. Assess the Severity of Missing Data\n",
        "\n",
        "Columns like veil-type, veil-color, stem-root, spore-print-color, gill-spacing, stem-surface, and cap-surface **have a large percentage of missing values.**\n",
        "\n",
        "These columns with more than **50% missing** data might not contribute meaningfully to your model and could be candidates for removal.\n",
        "\n",
        "#### 2. Decide on a Strategy\n",
        "\n",
        "Drop Columns: If a column has too many missing values (e.g., more than 50%), consider dropping it, especially if it‚Äôs unlikely to provide valuable information.\n",
        "\n",
        "Impute Missing Values: For columns with fewer missing values, we can fill in the missing data (imputation) using different strategies:\n",
        "\n",
        "    - For numerical columns like cap-diameter: Use the mean, median, or mode.\n",
        "    - For categorical columns like cap-shape, cap-color: Use the mode (most frequent value).\n",
        "    \n",
        "Custom Imputation: after  insights from EDA, we can use more sophisticated imputation techniques, such as filling based on other related columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1XIwXFWqudV"
      },
      "outputs": [],
      "source": [
        "missing_values = df.isnull().mean() * 100\n",
        "missing_values = missing_values[missing_values >0]\n",
        "missing_values = missing_values.sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=missing_values.index, y=missing_values.values, palette='viridis')\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Percentage of Missing Values')\n",
        "plt.title('Missing Values Distribution in df_train')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1MBiJv1qudV"
      },
      "source": [
        "**i Will remove this columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yev8auehqudV"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = ['veil-type', 'veil-color', 'stem-root', 'spore-print-color',]\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "test_df = test_df.drop(columns=columns_to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqLvgUc0qudW"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# For categorical features\n",
        "categorical_cols = ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed',\n",
        "                    'gill-attachment', 'gill-spacing', 'gill-color',\n",
        "                    'stem-surface', 'stem-color',\n",
        "                    'has-ring', 'ring-type', 'habitat']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)  # Replace NaN with the mode\n",
        "\n",
        "# For numerical features\n",
        "numerical_cols = ['cap-diameter']\n",
        "\n",
        "for col in numerical_cols:\n",
        "    df[col].fillna(df[col].median(), inplace=True)  # Replace NaN with the median\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FisWrCJtqudW"
      },
      "source": [
        "#### **Becouse i work with XGoost model which do imputation automatic i iwll not do it with my self i tryed but when i left the missin to the XGboost he did better**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jJqTanJqudW"
      },
      "source": [
        "## Class Distribution ( Data Imbalance ?? )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv3qABWSqudW"
      },
      "source": [
        "To understand the class imbalance in our dataset, you can check the distribution of the target variable (class) to see how many mushrooms are labeled as edible (e) and how many are labeled as poisonous (p).\n",
        "\n",
        "#### **1. Check Class Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvVA6YuLqudW"
      },
      "outputs": [],
      "source": [
        "# Get the counts of each class\n",
        "class_counts = df['class'].value_counts()\n",
        "\n",
        "# Calculate the percentage of each class\n",
        "class_percentage = df['class'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Display the counts and percentages\n",
        "class_distribution = pd.DataFrame({'Count': class_counts, 'Percentage': class_percentage})\n",
        "print(class_distribution)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P85z45PyqudX"
      },
      "source": [
        "#### **3. Interpret the Results**\n",
        "\n",
        "If the classes are relatively balanced (close to 50-50), you may not need to do anything special.\n",
        "\n",
        "If the classes are imbalanced (e.g., 90-10), you'll need to consider strategies to address this, such as:\n",
        "    - Resampling: Either oversample the minority class or undersample the majority class.\n",
        "    - Use of Algorithms: Some algorithms like XGBoost or Random Forest handle imbalance better.\n",
        "    - Class Weights: Assign higher weights to the minority class during model training.\n",
        "\n",
        "\n",
        "In our Data its clear that its Have a good Distribution **around 50% for each class** so we don't need to do some this here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oegwLVhqudX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot the class distribution\n",
        "sns.countplot(x='class', data=df)\n",
        "plt.title('Class Distribution of Mushrooms (Edible vs Poisonous)')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5SssPj5qudX"
      },
      "source": [
        "## OutLiers Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWx8KyfcqudX"
      },
      "source": [
        " Checking for outliers is an essential step in data preprocessing, especially in numerical features, as outliers can significantly impact your model's performance.\n",
        "\n",
        "**Visualizing Outliers Using Box Plots**\n",
        "\n",
        "Box plots are a great way to visually identify outliers. Here‚Äôs how you can create box plots for the numerical features in your dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHn4eQcbqudX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# List of numerical columns to check for outliers\n",
        "numerical_columns = ['cap-diameter', 'stem-height', 'stem-width']\n",
        "\n",
        "# Plotting box plots for each numerical feature\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, column in enumerate(numerical_columns, 1):\n",
        "    plt.subplot(1, len(numerical_columns), i)\n",
        "    sns.boxplot(x=df[column])\n",
        "    plt.title(f'Box Plot of {column}')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiNLAW7NqudY"
      },
      "outputs": [],
      "source": [
        "# Function to detect outliers using the IQR method\n",
        "def detect_outliers_iqr(data, column):\n",
        "    Q1 = data[column].quantile(0.25)\n",
        "    Q3 = data[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "\n",
        "# Apply the function to each numerical column\n",
        "for column in numerical_columns:\n",
        "    outliers = detect_outliers_iqr(df, column)\n",
        "    print(f\"Number of outliers in {column}: {outliers.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT-IGqGWqudY"
      },
      "source": [
        "Okey It looks like we have a outliers here, we cant consider all of this as outliers becouse some of them are logicaly true value\n",
        "\n",
        "#### **How Handling Outliers**\n",
        "Once you‚Äôve identified outliers, you have several options:\n",
        "\n",
        "**Remove Outliers**: If the outliers are likely errors or not relevant, you can remove them\n",
        "\n",
        "**Cap Outliers**: Replace outliers with the upper or lower bound of the non-outlier data.\n",
        "python\n",
        "\n",
        "i will drop for now only the very high outlier bettwen (0.01, 0.99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKBAm0tHqudY"
      },
      "outputs": [],
      "source": [
        "# Function to detect outliers using the IQR method\n",
        "def detect_outliers_iqr(data, column):\n",
        "    Q1 = data[column].quantile(0.01)\n",
        "    Q3 = data[column].quantile(0.99)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "for column in numerical_columns:\n",
        "    outliers = detect_outliers_iqr(df, column)\n",
        "    print(f\"Number of outliers in {column}: {outliers.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXK-DfCoqudZ"
      },
      "outputs": [],
      "source": [
        "# Removing outliers from each numerical column\n",
        "for column in numerical_columns:\n",
        "    df = df[~df.index.isin(detect_outliers_iqr(df, column).index)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkIjq7o-qudZ"
      },
      "source": [
        "## 2. Univariate Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNR1xfZ5qudZ"
      },
      "source": [
        "# Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiNjncXPqudZ"
      },
      "source": [
        "Lets first check the value counts in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Kb8pbh9qudb"
      },
      "outputs": [],
      "source": [
        "cat_cols = [col for col in df.columns if df[col].dtypes == \"O\"]\n",
        "df[cat_cols].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9nQPB12qudb"
      },
      "source": [
        "#### **Okey Now there is a problem We uselly use ONE HOT ENCODING but if we used it we will have a very very big number of features which will be hard to intterapt**\n",
        "\n",
        "#### **So we can perform rare encoding followed by either one-hot encoding or label encoding based on the number of unique classes in each categorical variable.**\n",
        "\n",
        "**threshold=0.01: This defines the threshold for rare encoding, meaning any class that appears in less than 1% of the data will be labeled as 'Rare'.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJo7ci1Zqudb"
      },
      "outputs": [],
      "source": [
        "def rare_encoding(df, threshold=0.01):\n",
        "    for column in df.select_dtypes(include='object').columns:\n",
        "        if column in df.columns:\n",
        "            freq = df[column].value_counts(normalize=True)\n",
        "            rare_classes = freq.index[freq < threshold]\n",
        "            df[column] = df[column].where(~df[column].isin(rare_classes), 'Rare')\n",
        "    return df\n",
        "\n",
        "# Separate the target column\n",
        "target = df['class']\n",
        "df_features = df.drop(columns=['class'])\n",
        "\n",
        "# Apply rare encoding to both datasets\n",
        "df_features = rare_encoding(df_features)\n",
        "test_df = rare_encoding(test_df)\n",
        "\n",
        "# Align columns\n",
        "common_cols = df_features.columns.intersection(test_df.columns)\n",
        "df_features = df_features[common_cols]\n",
        "test_df = test_df[common_cols]\n",
        "\n",
        "# Reattach the target column\n",
        "df = pd.concat([df_features, target], axis=1)\n",
        "\n",
        "# Verify columns\n",
        "print(\"df columns:\", df.columns)\n",
        "print(\"test_df columns:\", test_df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0jeKNWxqudh"
      },
      "outputs": [],
      "source": [
        "print(df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50O2khIwqudh"
      },
      "outputs": [],
      "source": [
        "df[cat_cols].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcdZO1iiqudh"
      },
      "source": [
        "#### **Choose Encoding Method**\n",
        "\n",
        "After rare encoding, we can decide between one-hot encoding and label encoding based on the number of unique classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT1S3obkqudh"
      },
      "outputs": [],
      "source": [
        "def encode_categorical(df, target_column=None, max_unique_classes=10):\n",
        "    for column in df.select_dtypes(include='object').columns:\n",
        "        if column != target_column:\n",
        "            unique_classes = df[column].nunique()\n",
        "            if unique_classes <= max_unique_classes:\n",
        "                df = pd.get_dummies(df, columns=[column], drop_first=True)\n",
        "            else:\n",
        "                le = LabelEncoder()\n",
        "                df[column] = le.fit_transform(df[column])\n",
        "    return df\n",
        "\n",
        "# Separate the target column\n",
        "target = df['class']\n",
        "df_features = df.drop(columns=['class'])\n",
        "\n",
        "# Apply encoding\n",
        "df_features = encode_categorical(df_features)\n",
        "test_df = encode_categorical(test_df)\n",
        "\n",
        "# Ensure both datasets have the same columns\n",
        "common_cols = df_features.columns.intersection(test_df.columns)\n",
        "df_features = df_features[common_cols]\n",
        "test_df = test_df[common_cols]\n",
        "\n",
        "# Reattach the target column\n",
        "df = pd.concat([df_features, target], axis=1)\n",
        "\n",
        "# Verify columns\n",
        "print(\"df columns:\", df.columns)\n",
        "print(\"test_df columns:\", test_df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV5nZOlqqudi"
      },
      "outputs": [],
      "source": [
        "print(df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kreAGiJpqudj"
      },
      "outputs": [],
      "source": [
        "# Map the target 'class' column to 0 and 1\n",
        "df['class'] = df['class'].map({'e': 0, 'p': 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N46-z8pqudj"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhJtcdeVqudj"
      },
      "source": [
        "Feature selection involves identifying the most relevant features that contribute to the model‚Äôs predictive power.\n",
        "i will try 4 ways to do that"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEv6bwMtqudj"
      },
      "source": [
        "## **Correlation Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIalrCI1qudj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18, 12))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxCbb3waqudj"
      },
      "source": [
        "Okey it's clear that we can't know any thing from this heatmap so we will use the otherways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVkMMzd5qudk"
      },
      "source": [
        "## **Univariate Feature Selection**\n",
        "\n",
        "\n",
        "techniques like **SelectKBest** to select features based on **statistical** tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytvYY_OVqudk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming X is a pandas DataFrame and y is the target column in the DataFrame\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# Impute missing values with the median for numerical features\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Convert imputed data back to a DataFrame\n",
        "X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns)\n",
        "\n",
        "# Perform feature selection\n",
        "selector = SelectKBest(score_func=chi2, k=10)\n",
        "X_new = selector.fit_transform(X_imputed_df, y)\n",
        "\n",
        "# Get selected feature names\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "print(\"Selected features:\", selected_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZisjldJqudk"
      },
      "outputs": [],
      "source": [
        "'''Selected= ['class', 'cap-diameter', 'stem-width', 'cap-shape_b', 'gill-attachment_a',\n",
        "       'gill-attachment_e', 'gill-attachment_p', 'stem-surface_g',\n",
        "       'stem-color_w', 'ring-type_z', 'season_w']\n",
        "testSelected= ['cap-diameter', 'stem-width', 'cap-shape_b', 'gill-attachment_a',\n",
        "       'gill-attachment_e', 'gill-attachment_p', 'stem-surface_g',\n",
        "       'stem-color_w', 'ring-type_z', 'season_w']\n",
        "df_SELECTED = df[Selected]\n",
        "df.shape\n",
        "test_df_SELECTED = test_df[testSelected]'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ6FT9Wdqudl"
      },
      "source": [
        "### **Its not logic for me he takes a classes from the same features and left the others !!**\n",
        "### i tried it any way but ofcourse i got bad accuracy that without delete the features\n",
        "### **So i will leave the columns without selection for now**\n",
        "\n",
        "**i will try later :**\n",
        "\n",
        "**Recursive Feature Elimination (RFE) :** RFE selects features by recursively considering smaller sets of features. This method is particularly useful for model selection.\n",
        "\n",
        " **Feature Importance from Tree-Based Models :** Tree-based models like Random Forest or XGBoost can provide feature importance directly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRNf34Wkqudl"
      },
      "source": [
        "# Modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei55jCAXqudl"
      },
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X_train = df.drop('class', axis=1)\n",
        "y_train = df['class']\n",
        "\n",
        "# Test data (no target)\n",
        "X_test = test_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xsb1lPMlqudl"
      },
      "outputs": [],
      "source": [
        "# Define DataFrames for training and test data\n",
        "train_columns = set(df.columns)\n",
        "test_columns = set(test_df.columns)\n",
        "train_only_columns = train_columns - test_columns\n",
        "test_only_columns = test_columns - train_columns\n",
        "print(\"Columns in train_df but not in test_df:\")\n",
        "print(train_only_columns)\n",
        "print(\"\\nColumns in test_df but not in train_df:\")\n",
        "print(test_only_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-ghxf76qudm"
      },
      "outputs": [],
      "source": [
        "numeric_features = ['cap-diameter', 'stem-height', 'stem-width']\n",
        "\n",
        "# Extract numeric features for training and test datasets\n",
        "X_train_numeric = df[numeric_features]\n",
        "X_test_numeric = test_df[numeric_features]\n",
        "\n",
        "# Standardize the numeric features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_numeric)\n",
        "X_test_scaled = scaler.transform(X_test_numeric)\n",
        "\n",
        "df[numeric_features] = X_train_scaled\n",
        "test_df[numeric_features] = X_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJik4ZFJqudm"
      },
      "outputs": [],
      "source": [
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naSQhNe6qudm"
      },
      "outputs": [],
      "source": [
        "# mattews metrics for this competiton\n",
        "def mcc_metric(y_pred, dmatrix):\n",
        "    y_true = dmatrix.get_label()\n",
        "    y_pred = (y_pred > 0.5).astype(int)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "    return 'mcc', mcc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsrOef_yqudn"
      },
      "source": [
        "## XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10RT4mzwqudn"
      },
      "outputs": [],
      "source": [
        "#parameters={'n_estimators': 297, 'max_depth': 16, 'learning_rate': 0.03906159386409017, 'subsample': 0.6935900010487451, 'colsample_bytree': 0.5171160704967471, 'gamma': 0.00013710778966124443, 'lambda': 0.0017203271581656767, 'alpha': 8.501510750413265e-06, 'scale_pos_weight': 1.0017942891559255,'enable_categorical': True,'tree_method': 'hist'}\n",
        "\n",
        "\n",
        "parameters={'n_estimators': 297, 'max_depth': 19, 'learning_rate': 0.028333382496137323, 'subsample': 0.9947997083813288,\n",
        "            'colsample_bytree': 0.5336230391923533,\n",
        "            'gamma': 0.16126940334635828,\n",
        "            'early_stopping_rounds': 50 }\n",
        "\n",
        "\n",
        "xgb_optuna_params = {\n",
        "    'n_estimators': 10000,\n",
        "    'alpha': 0.0002,\n",
        "    'subsample': 0.60,\n",
        "    'colsample_bytree': 0.4,\n",
        "    'max_depth': 13,\n",
        "    'min_child_weight': 10,\n",
        "    'learning_rate': 0.002,\n",
        "    'gamma': 5.6e-08,\n",
        "    'early_stopping_rounds': 10,\n",
        "    # 'tree_method': 'gpu_hist',\n",
        "    # 'device': \"cuda\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QopGaUL6qudn"
      },
      "outputs": [],
      "source": [
        "# Initialize the XGBClassifier with the specified parameters\n",
        "xgb_model = XGBClassifier(**xgb_optuna_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXy-NqGiqudo"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train the model with the evaluation set\n",
        "xgb_model.fit(\n",
        "    X_train_split, y_train_split,\n",
        "    eval_set=[(X_val_split, y_val_split)],\n",
        "    verbose=200\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4RIi2yUqudo"
      },
      "outputs": [],
      "source": [
        "# Predict on the test data\n",
        "test_predictions = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on training data using train_test_split\n",
        "y_val_pred = xgb_model.predict(X_val_split)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "accuracy = accuracy_score(y_val_split, y_val_pred)\n",
        "mcc = matthews_corrcoef(y_val_split, y_val_pred)\n",
        "print(f'Validation MCC: {mcc:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_val_split, y_val_pred))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_val_split, y_val_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAgTLm5Equdo"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv(\"/kaggle/input/playground-series-s4e8/sample_submission.csv\")\n",
        "submission[\"class\"] = test_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxR2atf4qudp"
      },
      "outputs": [],
      "source": [
        "# Map the target 'class' column to 0 and 1\n",
        "submission['class'] = submission['class'].map({0: 'e', 1: 'p'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd-ThFMuqudp"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6dTphoNqudp"
      },
      "outputs": [],
      "source": [
        "# Define the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val_split, y_val_pred)\n",
        "# Convert the confusion matrix to a DataFrame for better visualization with seaborn\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix,\n",
        "                              index=['Actual Negative', 'Actual Positive'],\n",
        "                              columns=['Predicted Negative', 'Predicted Positive'])\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d', cmap='Blues',\n",
        "            linewidths=0.5, linecolor='black',\n",
        "            cbar_kws={'label': 'Number of Predictions'})\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnO6IdoNqudr"
      },
      "source": [
        "## LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72C0P0sSqudr"
      },
      "outputs": [],
      "source": [
        " ######## Still working in that #######\n",
        "\n",
        "# Define the hyperparameters for LGBMClassifier (adjusted for LGBM)\n",
        "#parameters = {'n_estimators': 1869, 'max_depth': 32, 'learning_rate': 0.010217690029650325,\n",
        "#              'subsample': 0.847713364798533, 'colsample_bytree': 0.9861945128452118,\n",
        "#              'min_child_weight': 3.584741970207093, 'reg_alpha': 0.5182335134716664, 'reg_lambda': 0.10566374380137711}\n",
        "\n",
        "# Define the parameters for LGBMClassifier\n",
        "\n",
        "lgb_params = {\n",
        "    'n_estimators': 2500,\n",
        "    'random_state': 42,\n",
        "    'max_bin': 1024,\n",
        "    'colsample_bytree': 0.6,\n",
        "    'reg_lambda': 80,\n",
        "    'verbosity': -1\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh7Cm3g_quds"
      },
      "outputs": [],
      "source": [
        "# Initialize the LGBMClassifier with the specified parameters\n",
        "lgb_model = LGBMClassifier(**lgb_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj7WNgM_quds"
      },
      "outputs": [],
      "source": [
        "# Train the model with the evaluation set\n",
        "lgb_model.fit(\n",
        "    X_train_split, y_train_split,\n",
        "    eval_set=[(X_val_split, y_val_split)],\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZuECjeBquds"
      },
      "outputs": [],
      "source": [
        "# Predict on the validation data\n",
        "y_val_pred = lgb_model.predict(X_val_split)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "accuracy = accuracy_score(y_val_split, y_val_pred)\n",
        "mcc = matthews_corrcoef(y_val_split, y_val_pred)\n",
        "print(f'Validation MCC: {mcc:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_val_split, y_val_pred))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_val_split, y_val_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHdj0MGBquds"
      },
      "source": [
        "## Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHcYt6yfquds"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "# Create a VotingClassifier ensemble\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[('xgb', xgb_model), ('lgbm', lgb_model)],\n",
        "    voting='soft'  # 'soft' voting to average predicted probabilities\n",
        ")\n",
        "\n",
        "# Train the ensemble model\n",
        "ensemble_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = ensemble_model.predict(X_val_split)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "accuracy = accuracy_score(y_val_split, y_val_pred)\n",
        "mcc = matthews_corrcoef(y_val_split, y_val_pred)\n",
        "print(f'Validation MCC: {mcc:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_val_split, y_val_pred))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_val_split, y_val_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZsgs2EPqudt"
      },
      "source": [
        "## XGBOOST Optuna hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKOqK1Ykqudu"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef, classification_report, confusion_matrix\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# Separate features and target\n",
        "X_train = df.drop('class', axis=1)\n",
        "y_train = df['class']\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_split_scaled = scaler.fit_transform(X_train_split)\n",
        "X_val_split_scaled = scaler.transform(X_val_split)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Define the hyperparameters to tune\n",
        "    param = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': 'logloss',\n",
        "        'use_label_encoder': False,\n",
        "        'random_state': 42,\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 200, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 12, 20),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 0.3)\n",
        "    }\n",
        "\n",
        "    # Initialize and train the XGBoost model\n",
        "    model = xgb.XGBClassifier(**param)\n",
        "    model.fit(X_train_split_scaled, y_train_split)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_val_pred = model.predict(X_val_split_scaled)\n",
        "\n",
        "    # Calculate the MCC\n",
        "    mcc = matthews_corrcoef(y_val_split, y_val_pred)\n",
        "\n",
        "    return mcc\n",
        "\n",
        "# Create a study object and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "\n",
        "# Train the best model on the entire training data\n",
        "best_model = xgb.XGBClassifier(**best_params, objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=42)\n",
        "best_model.fit(X_train_split_scaled, y_train_split)\n",
        "\n",
        "# Predict on the validation set with the best model\n",
        "y_val_pred = best_model.predict(X)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gzpsRkIqudv"
      },
      "source": [
        "#### **i got this as best parametars after tuning, i still working to enhance it**\n",
        "\n",
        "Trial 34 finished with value:  and parameters: {'n_estimators': 297, 'max_depth': 19, 'learning_rate': 0.028333382496137323, 'subsample': 0.9947997083813288, 'colsample_bytree': 0.5336230391923533, 'gamma': 0.16126940334635828}. Best is trial 34"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x23Jlg3Tqudv"
      },
      "source": [
        "## LGBMClassifier Optuna hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hUVJpFHqudv"
      },
      "outputs": [],
      "source": [
        "'''import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef, classification_report, confusion_matrix\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# Separate features and target\n",
        "X_train = df.drop('class', axis=1)\n",
        "y_train = df['class']\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_split_scaled = scaler.fit_transform(X_train_split)\n",
        "X_val_split_scaled = scaler.transform(X_val_split)\n",
        "X_test_scaled = scaler.transform(X_test)  # Scale the test data as well\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Define the hyperparameters to tune\n",
        "    param = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_logloss',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'random_state': 42,\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 200, 2000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 9, 35),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "        'subsample': trial.suggest_float('subsample', 0.8, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.8, 1.0),\n",
        "        'min_child_weight': trial.suggest_float('min_child_weight', 0.001, 10),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0)\n",
        "    }\n",
        "\n",
        "    # Initialize and train the LGBM model\n",
        "    model = lgb.LGBMClassifier(**param)\n",
        "    model.fit(X_train_split_scaled, y_train_split)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_val_pred = model.predict(X_val_split_scaled)\n",
        "\n",
        "    # Calculate the MCC\n",
        "    mcc = matthews_corrcoef(y_val_split, y_val_pred)\n",
        "\n",
        "    return mcc\n",
        "\n",
        "# Create a study object and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "\n",
        "# Train the best model on the entire training data\n",
        "best_model = lgb.LGBMClassifier(**best_params, objective='binary', metric='binary_logloss', boosting_type='gbdt', random_state=42)\n",
        "best_model.fit(X_train_split_scaled, y_train_split)\n",
        "\n",
        "# Predict on the validation set with the best model\n",
        "y_val_pred = best_model.predict(X_val_split_scaled)\n",
        "\n",
        "# Evaluate the best model\n",
        "accuracy = accuracy_score(y_val_split, y_val_pred)\n",
        "mcc = matthews_corrcoef(y_val_split, y_val_pred)\n",
        "\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')\n",
        "print(f'Validation MCC: {mcc:.4f}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_val_split, y_val_pred))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_val_split, y_val_pred))\n",
        "\n",
        "# Predict on the test data\n",
        "test_predictions = best_model.predict(X_test_scaled)'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_6d-L1iqudw"
      },
      "source": [
        "#### **i got this as best parametars for LGBMClassifier after tuning, i still working to enhance it**\n",
        "Trial 49 finished with\n",
        "and parameters: {'n_estimators': 1869, 'max_depth': 32, 'learning_rate': 0.010217690029650325, 'subsample': 0.847713364798533, 'colsample_bytree': 0.9861945128452118, 'min_child_weight': 3.584741970207093, 'reg_alpha': 0.5182335134716664, 'reg_lambda': 0.10566374380137711}. Best is trial 46"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXZX0YrWqudw"
      },
      "source": [
        "# Submition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcEfksfwqudw"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv(\"/kaggle/input/playground-series-s4e8/sample_submission.csv\")\n",
        "submission[\"class\"] = y_val_pred\n",
        "submission.to_csv('submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FbP-RrJqudx"
      },
      "source": [
        "#### **AS you see The accuracy is With XGBoost : 0.992**\n",
        "\n",
        "#### **the other metrics (f1-socre, recall, precision)is okey**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdXtu0o3qudx"
      },
      "source": [
        "#### **I am still Updating the notebook every day and trying to hyperparametar tuning and try another things to share with you**\n",
        "### **So please if you found it usefull UPVOTE me **\n",
        "### **Thanks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_INAnGX3tfrs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 9045607,
          "sourceId": 76727,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30746,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}